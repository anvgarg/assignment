{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvesh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(input,num_filters,n_Denselayers,dropout_rate,bottleneck=True):\n",
    "    temp = input\n",
    "    for i in range(int(n_Denselayers)):\n",
    "        if bottleneck:\n",
    "            BatchNorm = BatchNormalization()(temp)\n",
    "            relu = Activation('relu')(BatchNorm)\n",
    "            Conv2D_BottleNeck = Conv2D(4*num_filters, (1,1), use_bias=False ,padding='same')(relu)\n",
    "            if dropout_rate>0:\n",
    "                Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "            BatchNorm = BatchNormalization()(Conv2D_BottleNeck)\n",
    "        else:\n",
    "            BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        temp = concat\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(input.shape[3].value *compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 2 * num_filter \n",
    "n_Denselayers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "first_layer = Conv2D(filters=n_channels,kernel_size=(3,3),padding='same')(input)\n",
    "\n",
    "First_Block = dense_block(first_layer, num_filter,n_Denselayers, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = dense_block(First_Transition, num_filter,n_Denselayers, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = dense_block(Second_Transition, num_filter,n_Denselayers, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter,dropout_rate)\n",
    "\n",
    "output = output_layer(Third_Transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 24)   672         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 48)   5760        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 48)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 48)   192         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 12)   5184        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 12)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 132)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 48)   6336        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 48)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 48)   192         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 12)   5184        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 12)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 144)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 48)   6912        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 12)   5184        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 12)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 156)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 48)   7488        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 32, 48)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 12)   5184        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 32, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 168)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 168)  672         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 168)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 48)   8064        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 32, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 48)   192         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 48)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 12)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 32, 12)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 180)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 180)  720         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 180)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 48)   8640        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 32, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 48)   192         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 12)   5184        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 32, 12)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 192)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 192)  768         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 192)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 48)   9216        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 32, 48)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 48)   192         dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 48)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 12)   5184        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 32, 12)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32, 32, 204)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 204)  816         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 204)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 48)   9792        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 32, 32, 48)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 48)   192         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 48)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 12)   5184        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32, 32, 12)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 216)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 216)  864         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 216)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 108)  23328       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 32, 32, 108)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 108)  0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 108)  432         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 108)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 48)   5184        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 12)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 120)  480         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 120)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   5760        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 12)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 132)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 132)  528         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 132)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 48)   6336        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 12)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 144)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 144)  576         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 144)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 48)   6912        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 12)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 156)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 156)  624         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 156)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   7488        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 12)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 168)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 168)  672         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 168)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 48)   8064        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 48)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 12)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 180)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 180)  720         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 180)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 48)   8640        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 48)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 12)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 192)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 192)  768         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   9216        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 48)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 204)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 204)  816         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 204)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 48)   9792        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 48)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 48)   192         dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 12)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 216)  0           concatenate_24[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 216)  864         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 48)   10368       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 48)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 48)   192         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 16, 16, 12)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 228)  0           concatenate_25[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 228)  912         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 228)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 48)   10944       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 16, 16, 48)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 48)   192         dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 16, 16, 12)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 240)  0           concatenate_26[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 240)  960         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 240)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 48)   11520       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 16, 16, 48)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 48)   192         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 16, 16, 12)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 252)  0           concatenate_27[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 252)  1008        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 252)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 48)   12096       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 16, 16, 48)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 48)   192         dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 12)   5184        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 16, 16, 12)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 16, 16, 264)  0           concatenate_28[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 264)  1056        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 264)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 48)   12672       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 16, 16, 48)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 48)   192         dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 48)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 12)   5184        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 16, 16, 12)   0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 16, 16, 276)  0           concatenate_29[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 276)  1104        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 276)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 48)   13248       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 16, 16, 48)   0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 48)   192         dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 48)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 12)   5184        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 16, 16, 12)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 288)  0           concatenate_30[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 288)  1152        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 288)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 16, 16, 48)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 48)   192         dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 12)   5184        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 16, 16, 12)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 16, 16, 300)  0           concatenate_31[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 300)  1200        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 300)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 150)  45000       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 16, 16, 150)  0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 150)    0           dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 150)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 48)     7200        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 162)    648         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 162)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 48)     7776        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 174)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 174)    696         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 174)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 48)     8352        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 186)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 186)    744         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 186)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 48)     8928        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 198)    0           concatenate_35[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 198)    792         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 198)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 48)     9504        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 210)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 210)    840         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 210)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 48)     10080       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 222)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 222)    888         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 222)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 48)     10656       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 234)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 234)    936         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 234)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 48)     11232       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 246)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 246)    984         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 246)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 48)     11808       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 258)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 258)    1032        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 258)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 48)     12384       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 270)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 270)    1080        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 270)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 48)     12960       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 48)     0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 282)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 282)    1128        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 282)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 48)     13536       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 48)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 294)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 294)    1176        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 294)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 48)     14112       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 48)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 48)     192         dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 48)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 12)     5184        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 12)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 8, 8, 306)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 306)    1224        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 306)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 48)     14688       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 48)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 48)     192         dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 48)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 12)     5184        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 12)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 8, 8, 318)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 318)    1272        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 318)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 48)     15264       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 48)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 48)     192         dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 48)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 12)     5184        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 12)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 8, 8, 330)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 330)    1320        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 330)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 48)     15840       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 8, 8, 48)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 48)     192         dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 48)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 12)     5184        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 8, 8, 12)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 342)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 342)    1368        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 342)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 171)    58482       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 8, 8, 171)    0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 171)    0           dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 171)    684         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 171)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 171)    0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 684)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           6850        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 855,760\n",
      "Trainable params: 831,430\n",
      "Non-trainable params: 24,330\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1,momentum=0.9,decay=0.0001,nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=datagen.flow(x_train,y_train,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 218s 218ms/step - loss: 1.5071 - acc: 0.4518 - val_loss: 1.6255 - val_acc: 0.4481\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 1.1781 - acc: 0.5777 - val_loss: 1.5127 - val_acc: 0.5428\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 1.0225 - acc: 0.6358 - val_loss: 1.0690 - val_acc: 0.6452\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.9298 - acc: 0.6710 - val_loss: 1.0539 - val_acc: 0.6607\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.8665 - acc: 0.6953 - val_loss: 0.9308 - val_acc: 0.6983\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.8152 - acc: 0.7134 - val_loss: 0.9786 - val_acc: 0.6910\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.7744 - acc: 0.7278 - val_loss: 0.8657 - val_acc: 0.7211\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.7393 - acc: 0.7408 - val_loss: 0.9404 - val_acc: 0.7104\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.7101 - acc: 0.7511 - val_loss: 0.7345 - val_acc: 0.7610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.6850 - acc: 0.7606 - val_loss: 0.7690 - val_acc: 0.7584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44b5c9af98>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.6632 - acc: 0.7679 - val_loss: 0.7279 - val_acc: 0.7706\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.6435 - acc: 0.7742 - val_loss: 0.8088 - val_acc: 0.7549\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.6254 - acc: 0.7818 - val_loss: 0.7408 - val_acc: 0.7723\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.6075 - acc: 0.7874 - val_loss: 0.7025 - val_acc: 0.7833\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.5969 - acc: 0.7905 - val_loss: 0.6390 - val_acc: 0.7923\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.5827 - acc: 0.7962 - val_loss: 0.7183 - val_acc: 0.7732\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.5676 - acc: 0.8015 - val_loss: 0.7132 - val_acc: 0.7822\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.5581 - acc: 0.8055 - val_loss: 0.6985 - val_acc: 0.7927\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.5468 - acc: 0.8081 - val_loss: 0.7057 - val_acc: 0.7874\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.5352 - acc: 0.8140 - val_loss: 0.6217 - val_acc: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44b5c9a208>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('DNST_model_800_aug_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 0.5707 - acc: 0.8002 - val_loss: 0.6590 - val_acc: 0.7952\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.5521 - acc: 0.8070 - val_loss: 0.7005 - val_acc: 0.7872\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.5261 - acc: 0.8160 - val_loss: 0.6660 - val_acc: 0.7970\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.5085 - acc: 0.8217 - val_loss: 0.6463 - val_acc: 0.8053\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.4917 - acc: 0.8268 - val_loss: 0.6934 - val_acc: 0.7915\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4764 - acc: 0.8338 - val_loss: 0.6407 - val_acc: 0.8093\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.4648 - acc: 0.8371 - val_loss: 0.5004 - val_acc: 0.8446\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4547 - acc: 0.8414 - val_loss: 0.5804 - val_acc: 0.8241\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4462 - acc: 0.8433 - val_loss: 0.5467 - val_acc: 0.8291\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.4322 - acc: 0.8495 - val_loss: 0.5354 - val_acc: 0.8372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3fea46cc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4269 - acc: 0.8508 - val_loss: 0.5407 - val_acc: 0.8428\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4185 - acc: 0.8525 - val_loss: 0.5936 - val_acc: 0.8254\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.4096 - acc: 0.8562 - val_loss: 0.5581 - val_acc: 0.8290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 176s 176ms/step - loss: 0.3948 - acc: 0.8604 - val_loss: 0.6568 - val_acc: 0.8128\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3932 - acc: 0.8626 - val_loss: 0.5625 - val_acc: 0.8337\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3889 - acc: 0.8631 - val_loss: 0.5730 - val_acc: 0.8361\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3809 - acc: 0.8664 - val_loss: 0.5249 - val_acc: 0.8430\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3769 - acc: 0.8678 - val_loss: 0.5247 - val_acc: 0.8380\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3709 - acc: 0.8697 - val_loss: 0.5585 - val_acc: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3cabef9e8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3706 - acc: 0.8695 - val_loss: 0.4922 - val_acc: 0.8540\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3643 - acc: 0.8713 - val_loss: 0.5073 - val_acc: 0.8482\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3598 - acc: 0.8737 - val_loss: 0.4894 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3529 - acc: 0.8756 - val_loss: 0.4920 - val_acc: 0.8543\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.3504 - acc: 0.8775 - val_loss: 0.4922 - val_acc: 0.8539\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3464 - acc: 0.8783 - val_loss: 0.5286 - val_acc: 0.8472\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3462 - acc: 0.8778 - val_loss: 0.5335 - val_acc: 0.8452\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3402 - acc: 0.8811 - val_loss: 0.5028 - val_acc: 0.8526\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3348 - acc: 0.8823 - val_loss: 0.5036 - val_acc: 0.8520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.3337 - acc: 0.8829 - val_loss: 0.4934 - val_acc: 0.8563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3cabef828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.001,momentum=0.9,decay=0.0001,nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 202s 202ms/step - loss: 0.3228 - acc: 0.8857 - val_loss: 0.4778 - val_acc: 0.8582\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3186 - acc: 0.8875 - val_loss: 0.4776 - val_acc: 0.8614\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3162 - acc: 0.8887 - val_loss: 0.4756 - val_acc: 0.8628\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3178 - acc: 0.8879 - val_loss: 0.4844 - val_acc: 0.8553\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3118 - acc: 0.8902 - val_loss: 0.4753 - val_acc: 0.8600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3125 - acc: 0.8895 - val_loss: 0.4817 - val_acc: 0.8576\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3091 - acc: 0.8903 - val_loss: 0.4817 - val_acc: 0.8572\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3117 - acc: 0.8898 - val_loss: 0.4680 - val_acc: 0.8616\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3084 - acc: 0.8913 - val_loss: 0.4636 - val_acc: 0.8629\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3070 - acc: 0.8918 - val_loss: 0.4788 - val_acc: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3fea57908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.0001,momentum=0.9,decay=0.0001,nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 205s 205ms/step - loss: 0.3053 - acc: 0.8920 - val_loss: 0.4721 - val_acc: 0.8612\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3066 - acc: 0.8931 - val_loss: 0.4719 - val_acc: 0.8630\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 176s 176ms/step - loss: 0.3032 - acc: 0.8934 - val_loss: 0.4719 - val_acc: 0.8628\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3042 - acc: 0.8929 - val_loss: 0.4726 - val_acc: 0.8615\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 176s 176ms/step - loss: 0.3038 - acc: 0.8932 - val_loss: 0.4721 - val_acc: 0.8622\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3056 - acc: 0.8925 - val_loss: 0.4728 - val_acc: 0.8613\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 176s 176ms/step - loss: 0.3023 - acc: 0.8927 - val_loss: 0.4735 - val_acc: 0.8620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 176s 176ms/step - loss: 0.3041 - acc: 0.8928 - val_loss: 0.4727 - val_acc: 0.8619\n",
      "Epoch 9/10\n",
      " 882/1000 [=========================>....] - ETA: 20s - loss: 0.3030 - acc: 0.8923"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_6.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"DNST_model_800_aug_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 0.3978 - acc: 0.8598 - val_loss: 0.5758 - val_acc: 0.8271\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.3866 - acc: 0.8637 - val_loss: 0.7250 - val_acc: 0.7997\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.3785 - acc: 0.8673 - val_loss: 0.5618 - val_acc: 0.8427\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.3671 - acc: 0.8713 - val_loss: 0.6256 - val_acc: 0.8255\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.3599 - acc: 0.8729 - val_loss: 0.5690 - val_acc: 0.8441\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.3492 - acc: 0.8767 - val_loss: 0.5856 - val_acc: 0.8392\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 0.3455 - acc: 0.8779 - val_loss: 0.5490 - val_acc: 0.8502\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 0.3365 - acc: 0.8805 - val_loss: 0.6240 - val_acc: 0.8325\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 180s 180ms/step - loss: 0.3320 - acc: 0.8828 - val_loss: 0.5870 - val_acc: 0.8386\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.3275 - acc: 0.8833 - val_loss: 0.5316 - val_acc: 0.8517\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.3207 - acc: 0.8863 - val_loss: 0.7921 - val_acc: 0.7995\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.3154 - acc: 0.8885 - val_loss: 0.4922 - val_acc: 0.8653\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 178s 178ms/step - loss: 0.3075 - acc: 0.8918 - val_loss: 0.4920 - val_acc: 0.8639\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 177s 177ms/step - loss: 0.3035 - acc: 0.8917 - val_loss: 0.6675 - val_acc: 0.8225\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 179s 179ms/step - loss: 0.2964 - acc: 0.8963 - val_loss: 0.5357 - val_acc: 0.8573\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 185s 185ms/step - loss: 0.2946 - acc: 0.8962 - val_loss: 0.5084 - val_acc: 0.8620\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 183s 183ms/step - loss: 0.2851 - acc: 0.8983 - val_loss: 0.4938 - val_acc: 0.8682\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 0.2841 - acc: 0.8991 - val_loss: 0.4676 - val_acc: 0.8723\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 184s 184ms/step - loss: 0.2795 - acc: 0.9019 - val_loss: 0.5555 - val_acc: 0.8525\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 180s 180ms/step - loss: 0.2740 - acc: 0.9020 - val_loss: 0.7341 - val_acc: 0.8256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff11be89128>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_7.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.2438 - acc: 0.9142 - val_loss: 0.5254 - val_acc: 0.8662\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.2343 - acc: 0.9178 - val_loss: 0.4646 - val_acc: 0.8779\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.2264 - acc: 0.9206 - val_loss: 0.5000 - val_acc: 0.8716\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.2171 - acc: 0.9230 - val_loss: 0.4628 - val_acc: 0.8860\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.2109 - acc: 0.9250 - val_loss: 0.5284 - val_acc: 0.8730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 192s 192ms/step - loss: 0.2037 - acc: 0.9277 - val_loss: 0.4825 - val_acc: 0.8817\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.1962 - acc: 0.9308 - val_loss: 0.5031 - val_acc: 0.8759\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.1904 - acc: 0.9324 - val_loss: 0.5068 - val_acc: 0.8818\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.1830 - acc: 0.9346 - val_loss: 0.4898 - val_acc: 0.8805\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 191s 191ms/step - loss: 0.1814 - acc: 0.9360 - val_loss: 0.4709 - val_acc: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0151f03080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"DNST_model_800_aug_8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 214s 214ms/step - loss: 0.2727 - acc: 0.9040 - val_loss: 0.6020 - val_acc: 0.8458\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.2584 - acc: 0.9088 - val_loss: 0.5060 - val_acc: 0.8711\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.2411 - acc: 0.9134 - val_loss: 0.6976 - val_acc: 0.8323\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.2249 - acc: 0.9198 - val_loss: 0.4428 - val_acc: 0.8848\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.2167 - acc: 0.9228 - val_loss: 0.5166 - val_acc: 0.8763\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.2034 - acc: 0.9276 - val_loss: 0.4868 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1925 - acc: 0.9320 - val_loss: 0.4494 - val_acc: 0.8920\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1814 - acc: 0.9358 - val_loss: 0.5470 - val_acc: 0.8761\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.1760 - acc: 0.9377 - val_loss: 0.4962 - val_acc: 0.8848\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1712 - acc: 0.9382 - val_loss: 0.4992 - val_acc: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8acdebcc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1639 - acc: 0.9415 - val_loss: 0.5011 - val_acc: 0.8850\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1603 - acc: 0.9427 - val_loss: 0.4555 - val_acc: 0.8923\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1544 - acc: 0.9448 - val_loss: 0.4809 - val_acc: 0.8890\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1468 - acc: 0.9473 - val_loss: 0.5185 - val_acc: 0.8843\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1431 - acc: 0.9491 - val_loss: 0.4623 - val_acc: 0.8949\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1383 - acc: 0.9504 - val_loss: 0.4615 - val_acc: 0.8948\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1359 - acc: 0.9511 - val_loss: 0.4594 - val_acc: 0.8978\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.1315 - acc: 0.9524 - val_loss: 0.4306 - val_acc: 0.9008\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1286 - acc: 0.9541 - val_loss: 0.4718 - val_acc: 0.8995\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1263 - acc: 0.9552 - val_loss: 0.4739 - val_acc: 0.8942\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1195 - acc: 0.9578 - val_loss: 0.4906 - val_acc: 0.8970\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1182 - acc: 0.9581 - val_loss: 0.4755 - val_acc: 0.9002\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.1142 - acc: 0.9593 - val_loss: 0.4495 - val_acc: 0.9033\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1127 - acc: 0.9599 - val_loss: 0.4916 - val_acc: 0.8971\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1117 - acc: 0.9597 - val_loss: 0.5048 - val_acc: 0.8927\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1078 - acc: 0.9613 - val_loss: 0.4400 - val_acc: 0.9056\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1056 - acc: 0.9621 - val_loss: 0.5241 - val_acc: 0.8975\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1066 - acc: 0.9618 - val_loss: 0.4743 - val_acc: 0.9045\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.1032 - acc: 0.9634 - val_loss: 0.4442 - val_acc: 0.9051\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0986 - acc: 0.9651 - val_loss: 0.4584 - val_acc: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8acdeb1d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0989 - acc: 0.9643 - val_loss: 0.4799 - val_acc: 0.9048\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0969 - acc: 0.9655 - val_loss: 0.5102 - val_acc: 0.8963\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0951 - acc: 0.9659 - val_loss: 0.4800 - val_acc: 0.9036\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0963 - acc: 0.9650 - val_loss: 0.4743 - val_acc: 0.9021\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0931 - acc: 0.9666 - val_loss: 0.5016 - val_acc: 0.8966\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0915 - acc: 0.9670 - val_loss: 0.5453 - val_acc: 0.8950\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0909 - acc: 0.9670 - val_loss: 0.4748 - val_acc: 0.9017\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0883 - acc: 0.9681 - val_loss: 0.4823 - val_acc: 0.9035\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0887 - acc: 0.9686 - val_loss: 0.4981 - val_acc: 0.9023\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0862 - acc: 0.9696 - val_loss: 0.4835 - val_acc: 0.9046\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0854 - acc: 0.9698 - val_loss: 0.4968 - val_acc: 0.9010\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0836 - acc: 0.9702 - val_loss: 0.4816 - val_acc: 0.9043\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0830 - acc: 0.9707 - val_loss: 0.4956 - val_acc: 0.9042\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.0822 - acc: 0.9705 - val_loss: 0.4531 - val_acc: 0.9077\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.0822 - acc: 0.9707 - val_loss: 0.4740 - val_acc: 0.9044\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0808 - acc: 0.9716 - val_loss: 0.4866 - val_acc: 0.9057\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.0787 - acc: 0.9713 - val_loss: 0.5161 - val_acc: 0.8998\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0775 - acc: 0.9720 - val_loss: 0.4958 - val_acc: 0.9071\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.0771 - acc: 0.9725 - val_loss: 0.5432 - val_acc: 0.9004\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0763 - acc: 0.9729 - val_loss: 0.4981 - val_acc: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd878fb65c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0379 - acc: 0.9870 - val_loss: 0.4247 - val_acc: 0.9170\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0313 - acc: 0.9889 - val_loss: 0.4550 - val_acc: 0.9138\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0286 - acc: 0.9903 - val_loss: 0.4362 - val_acc: 0.9178\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0278 - acc: 0.9903 - val_loss: 0.4338 - val_acc: 0.9173\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.4394 - val_acc: 0.9184\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.4276 - val_acc: 0.9210\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0226 - acc: 0.9924 - val_loss: 0.4340 - val_acc: 0.9196\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.4515 - val_acc: 0.9169\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0207 - acc: 0.9931 - val_loss: 0.4414 - val_acc: 0.9198\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0217 - acc: 0.9928 - val_loss: 0.4479 - val_acc: 0.9187\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0198 - acc: 0.9930 - val_loss: 0.4566 - val_acc: 0.9188\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0208 - acc: 0.9928 - val_loss: 0.4547 - val_acc: 0.9210\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.4552 - val_acc: 0.9200\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.4553 - val_acc: 0.9210\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0181 - acc: 0.9941 - val_loss: 0.4686 - val_acc: 0.9174\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.4513 - val_acc: 0.9205\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0173 - acc: 0.9944 - val_loss: 0.4630 - val_acc: 0.9209\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.4676 - val_acc: 0.9204\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.4774 - val_acc: 0.9193\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.4624 - val_acc: 0.9209\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0154 - acc: 0.9946 - val_loss: 0.4792 - val_acc: 0.9199\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.4774 - val_acc: 0.9195\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.4876 - val_acc: 0.9177\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0159 - acc: 0.9949 - val_loss: 0.4661 - val_acc: 0.9205\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.4859 - val_acc: 0.9200\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0143 - acc: 0.9954 - val_loss: 0.4797 - val_acc: 0.9188\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0141 - acc: 0.9951 - val_loss: 0.4640 - val_acc: 0.9216\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.4791 - val_acc: 0.9212\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.4816 - val_acc: 0.9183\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.4812 - val_acc: 0.9199\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.4873 - val_acc: 0.9198\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.4686 - val_acc: 0.9214\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.4924 - val_acc: 0.9196\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.4845 - val_acc: 0.9208\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0126 - acc: 0.9959 - val_loss: 0.4961 - val_acc: 0.9184\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.5009 - val_acc: 0.9186\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0121 - acc: 0.9962 - val_loss: 0.4805 - val_acc: 0.9206\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.4817 - val_acc: 0.9207\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.4853 - val_acc: 0.9207\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.4769 - val_acc: 0.9215\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.4979 - val_acc: 0.9196\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.4842 - val_acc: 0.9200\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.4886 - val_acc: 0.9205\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.4860 - val_acc: 0.9201\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.4905 - val_acc: 0.9236\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.4956 - val_acc: 0.9210\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.5016 - val_acc: 0.9208\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.4951 - val_acc: 0.9227\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.4978 - val_acc: 0.9214\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.4983 - val_acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8784fe4e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"DNST_model_800_aug_12.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
